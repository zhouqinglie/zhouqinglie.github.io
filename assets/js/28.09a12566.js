(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{514:function(t,s,a){"use strict";a.r(s);var n=a(2),p=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",[t._v("基础知识及鸢尾花识别实例解析"),a("br")])]),t._v(" "),a("p",[t._v("人工智能的主流：连接主义。")]),t._v(" "),a("h3",{attrs:{id:"人工智能的三个学派"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#人工智能的三个学派"}},[t._v("#")]),t._v(" 人工智能的三个学派：")]),t._v(" "),a("p",[t._v("1、行为主义：基于控制论，由感知到控制。")]),t._v(" "),a("p",[t._v("2、符号主义：基于表达式，先描述表达式，再求解表达式，是一种用公式描述的人工智能。")]),t._v(" "),a("p",[t._v("3、连接主义：仿生学，神经网络的感性控制。")]),t._v(" "),a("h3",{attrs:{id:"搭建一个完整的神经网络-往往需要以下几个步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#搭建一个完整的神经网络-往往需要以下几个步骤"}},[t._v("#")]),t._v(" 搭建一个完整的神经网络，往往需要以下几个步骤：")]),t._v(" "),a("p",[t._v("1、准备数据：特征和标签对（数据集）")]),t._v(" "),a("p",[t._v("2、搭建网络：确定神经网络的结构")]),t._v(" "),a("p",[t._v("3、优化参数：（利用反向传播）获取最佳参数")]),t._v(" "),a("p",[t._v("4、应用网络：保存训练模型，应用（前向传播）")]),t._v(" "),a("p",[t._v("神经网络的表达式：y=w*x+b     y表示期望，w表示权重，b表示偏置，在最初的设计中，w和b都是随机设置的。")]),t._v(" "),a("p",[t._v("损失函数：预测期望值与实际值的差距，根据损失函数去判断参数w、b优化的好坏，是否还需要继续优化。常见的是均方误差（MSE），目的就是找到使损失函数最小的w和b。")]),t._v(" "),a("p",[t._v("梯度：损失函数对各参数求偏导后的向量，梯度下降的方向即损失函数变小的方向，沿着梯度的下降方向寻找损失函数的最小值。")]),t._v(" "),a("p",[t._v("迭代函数：wt=wt-lr*（loss对w的偏导）    wt表示参数，lr表示迭代速率")]),t._v(" "),a("h3",{attrs:{id:"tensor-张量-多维数组"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tensor-张量-多维数组"}},[t._v("#")]),t._v(" Tensor：张量，多维数组")]),t._v(" "),a("p",[t._v("拥有的数据类型：int、float（32,64）、bool、string")]),t._v(" "),a("p",[t._v("创建张量tensor：tf.constant(张量内容，形状，dtype=数据类型)")]),t._v(" "),a("p",[t._v("张量内容如果是一个数值，那么在张量内部都会填充为该数值。")]),t._v(" "),a("p",[t._v("tf.constant([1 5], shape=(2，)， dtype=int64)    表示是一个两行，第一行为1第二行为5的整型张量。")]),t._v(" "),a("p",[t._v("对于numpy格式的数据，要用tf.convert_to_tensor(a,dtype=)转变为tensor。")]),t._v(" "),a("p",[t._v("创建全为0的张量：tf.zeros(维度)")]),t._v(" "),a("p",[t._v("创建全为1的张量：tf.ones（维度）")]),t._v(" "),a("p",[t._v("创建全为指定值的张量：tf.fill（维度，指定值）")]),t._v(" "),a("p",[t._v("生成正态分布的随机数，默认均值为0，标准差为1   tf.random.normal(维度，mean=均值，stddev=标准差)")]),t._v(" "),a("p",[t._v("生成截断式正态分布的随机数   tf.random.truncated_normal(维度，mean=均值，stddev=标准差)")]),t._v(" "),a("p",[t._v("生成均匀分布随机数   tf.random.uniform(维度，minval=最小值，maxval=最大值) 最小最大为前闭后开区间")]),t._v(" "),a("h3",{attrs:{id:"常见函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#常见函数"}},[t._v("#")]),t._v(" 常见函数：")]),t._v(" "),a("p",[t._v("强制转换类型函数：tf.cast（A张量名，dtype=数据类型）  表明要将张量A转变为dtype后的数据类型")]),t._v(" "),a("p",[t._v("计算张量维度元素上的最小值：tf.reduce_min（张量A）")]),t._v(" "),a("p",[t._v("计算张量维度元素上的最大值：tf.reduce_max（张量A）")]),t._v(" "),a("p",[t._v("axis：指定axis等于0或1，来控制被执行的行与列。")]),t._v(" "),a("p",[t._v("axis=0，表示沿着行垂直往下（列）；axis=1，表示沿着列水平向右（行），如果不指定axis，则所有元素都参与计算。")]),t._v(" "),a("p",[t._v("tf.varuable(初始值)：")]),t._v(" "),a("p",[t._v("将变量标记为“可训练”，被标记的变量会在反向传播中记录梯度信息。神经网络训练汇总，常用该函数标记带训练参数。")]),t._v(" "),a("h3",{attrs:{id:"四则运算"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四则运算"}},[t._v("#")]),t._v(" 四则运算：")]),t._v(" "),a("p",[t._v("tf.add/subtract/multiply/divide（张量1，张量2），分别表示+-*/，只有相同维度的张量才可以进行四则运算。")]),t._v(" "),a("p",[t._v("平方：tf.square(张量)")]),t._v(" "),a("p",[t._v("次方：tf.pow(张量)")]),t._v(" "),a("p",[t._v("开方：tf.sqrt(张量）")]),t._v(" "),a("p",[t._v("矩阵乘：tf.matmul（a，b）   a，b必须符合矩阵的运算要求")]),t._v(" "),a("h3",{attrs:{id:"鸢尾花实例及解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#鸢尾花实例及解析"}},[t._v("#")]),t._v(" 鸢尾花实例及解析：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -*- coding: UTF-8 -*-")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# UTF-8编码解码器，使计算机能正确识别中文")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 导入所需模块")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tf  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#引入tensorflow包，并重命名为tf，后续的tf即表示tensorflow（用于神经网络搭建）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datasets   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从sklearn包下载datasets数据集")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" matplotlib "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从matplotlib包引入pyplot函数，并重命名为plt（用于记录数据绘图输出图形）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#引入numpy包重命名为np（用于数值计算和数据扩展）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#一、准备数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ①数据集读入")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 导入数据，分别为输入特征和标签")]),t._v("\nx_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#表示从datasets加载iris的特征数据")]),t._v("\ny_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("target  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#表示从datasets加载iris的标签")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#②数据集乱序")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shuffle用来吧一个列表中的元素顺序随机打乱")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("116")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用相同的seed，保证输入特征和标签一一对应，先设置随机数，再执行乱序的shuffle操作")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("116")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#设置操作级别的种子数")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时x与y被打乱，但二者的特征和标签仍旧一一对应")]),t._v("\ntf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("116")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#设置全局种子数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#③生成训练集及测试集")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行")]),t._v("\nx_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ny_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nx_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ny_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 矩阵相乘时要求数据类型是一致的")]),t._v("\nx_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#转换类型")]),t._v("\nx_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#同上")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#④配成（输入特征与标签对），每次读入一小撮")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）")]),t._v("\ntrain_db "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将训练组的x与y对应起来，后边加.batch表示将该数据组按照每32个一组组成一个batch")]),t._v("\ntest_db "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将测试组的x与y对应起来")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 二搭建神经网络")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成神经网络的参数，4个输入特征（鸢尾花有四个特征测量数据），输入层为4个输入节点；因为3分类，故输出层为3个神经元")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用tf.Variable()标记参数可训练")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）")]),t._v("\nw1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("truncated_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stddev"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#标记w1是可训练参数，然后随机生成一个截取正态范围内的一部分作为随机数生成的区间（表示生成了一个四行三列，标准差为0.1，随机种子为1的矩阵）")]),t._v("\nb1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("truncated_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stddev"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# b1作为偏置项，衡量的是一个神经元激活的难易程度，越大越难以被激活，通过对b的优化，使各个神经元达到最合适的激活状态")]),t._v("\nlr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学习率为0.1，即沿着梯度下降方向的步长")]),t._v("\ntrain_loss_results "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义了一个列表（()为元组不可变，[]为列表可变，{}为字典），将每轮的loss记录在此列表中，为后续画loss曲线提供数据")]),t._v("\ntest_acc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义了一个列表，将每轮的acc记录在此列表中，为后续画acc曲线提供数据")]),t._v("\nepoch "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 循环500轮")]),t._v("\nloss_all "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每轮分4个step，loss_all记录四个step生成的4个loss的和")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练部分")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 120个数据分为每32个数据一组，进行训练。训练500epoch（轮）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#for循环进行迭代训练（for往往针对的是次数已知的循环，while针对的是次数未知的），数据集级别的循环，每个epoch循环一次数据集")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#batch级别的循环 ，每个step循环一个batch")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# enumerate函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientTape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" tape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# with，上下文管理器，该结构记录梯度信息")]),t._v("\n            y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b1  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 神经网络矩阵乘法与加法运算，完成y=w*x+b的运算")]),t._v("\n            y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使输出y（预测值）符合概率分布（此操作后与独热码同量级，可相减求loss）")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# softmax层的输入是全连接，输出是0-1之间的一个概率值，取最大的为输出结果")]),t._v("\n            y_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("one_hot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" depth"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将标签值（实际值）转换为独热码格式，方便计算loss和accuracy")]),t._v("\n            loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 损失函数采用均方误差mse = mean(sum(y-out)^2)，可以消除正负值带来的影响")]),t._v("\n            loss_all "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算loss对各个参数的梯度")]),t._v("\n        grads "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gradient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# gradient函数，求梯度")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad")]),t._v("\n        w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assign_sub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 参数w1自更新，assign_sub 自减")]),t._v("\n        b1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assign_sub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 参数b自更新")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对每个epoch，打印loss信息")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Epoch {}, loss: {}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_all"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    train_loss_results"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss_all "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 给train_loss_results追加内容，将4个step的loss求平均记录在此变量中")]),t._v("\n    loss_all "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# loss_all归零，为记录下一个epoch的loss做准备")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 测试部分")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0")]),t._v("\n    total_correct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" total_number "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" test_db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用更新后的参数进行预测")]),t._v("\n        y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b1\n        y "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# argmax 返回y中最大值的索引，即预测的分类")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将pred转换为y_test的数据类型")]),t._v("\n        pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtype"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#cast 强制转换数据类型，后边跟某个变量，指的是转变成该变量的格式")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型")]),t._v("\n        correct "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#比较pred和y_test的数据类型，二者的形式要一致，否则不能进行比较")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 相同输出true，不同输出false")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将每个batch的correct数加起来")]),t._v("\n        correct "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("correct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将所有batch中的correct数加起来")]),t._v("\n        total_correct "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("correct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数，0表示返回一个数")]),t._v("\n        total_number "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 总的准确率等于total_correct/total_number")]),t._v("\n    acc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" total_correct "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" total_number\n    test_acc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("acc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Test_acc:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" acc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"--------------------------"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 绘制 loss 曲线，plt绘图函数")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Loss Function Curve'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 图片标题")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Epoch'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# x轴变量名称")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Loss'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y轴变量名称")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_loss_results"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$Loss$"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐点画出trian_loss_results值并连线，连线图标是Loss")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 画出曲线图标")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 画出图像")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 绘制 Accuracy 曲线")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Acc Curve'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 图片标题")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Epoch'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# x轴变量名称")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Acc'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y轴变量名称")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_acc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$Accuracy$"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐点画出test_acc值并连线，连线图标是Accuracy")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=p.exports}}]);
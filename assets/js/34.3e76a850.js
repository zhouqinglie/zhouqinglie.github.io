(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{524:function(t,a,s){"use strict";s.r(a);var n=s(2),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("div",{staticClass:"custom-block tip"},[s("p",[t._v("拟合、保存与调参"),s("br")])]),t._v(" "),s("p",[t._v("PIL 图像处理包    PLT表格数据展示包")]),t._v(" "),s("p",[t._v("Train_images=train_images/255")]),t._v(" "),s("p",[t._v("Test_images=test_images/255")]),t._v(" "),s("h2",{attrs:{id:"预处理数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#预处理数据"}},[t._v("#")]),t._v(" 预处理数据")]),t._v(" "),s("p",[t._v("在训练神经网络之前，必须对数据进行处理。训练集中图片的像素大小往往是一致的，目前常见的典型学习神经网络有数字识别和服装识别两个。")]),t._v(" "),s("p",[t._v("在mnist数据集中，如果要预测新的数据，输入的图片必须满足28*28，否则程序就会难以识别。")]),t._v(" "),s("p",[t._v("而图片（灰度图）上每一个点的像素值都是0-255（0表示全白，255表示全黑），在预处理阶段会对图片进行压缩，使像素值缩小到0-1之间（便于网络吸收），将其反馈到神经网络。如果输入的是彩色图片，还要对图片进行灰度化处理。")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("\nModel"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sequential"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n\nTf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_shape"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("28")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("28")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\nTf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("activation"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#表示该层有128个神经元，激活函数为relu函数")]),t._v("\n\nTf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#全连接层，也是输出层，输出层的神经元个数与可能的输出结果数有关")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("h2",{attrs:{id:"tf-keras-layers-flatten-拉直层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tf-keras-layers-flatten-拉直层"}},[t._v("#")]),t._v(" Tf.keras.layers.flatten() ：拉直层")]),t._v(" "),s("p",[t._v("将图像从二维数组28"),s("em",[t._v("28，转换为一维数组（28")]),t._v("28=784个像素点，排列为一排）。将该层视为未曾堆叠的像素行并将其排列。该层板并没有参数，也不需要对齐进行训练，只是对原始数据进行处理，格式化数据。")]),t._v(" "),s("h2",{attrs:{id:"tf-keras-layers-dense-全连接层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tf-keras-layers-dense-全连接层"}},[t._v("#")]),t._v(" Tf.keras.layers.dense（）：全连接层")]),t._v(" "),s("p",[t._v("括号内写神经元个数和参数")]),t._v(" "),s("p",[t._v("损失函数最小，使预测贴近真实。")]),t._v(" "),s("p",[t._v("优化器：决定参数如何进行更新")]),t._v(" "),s("p",[t._v("指标：监控训练和测试步骤。")]),t._v(" "),s("p",[t._v("准确率：图像被准确识别的比率")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("\nModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimzer"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("‘adam’，\nLoss"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparaseCategoricalCrossentropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_logits"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#损失函数取得是交叉熵函数，括号内参数根据输出的y值是概率值还是真实值来确定")]),t._v("\nMetrics"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'accuracy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#衡量识别准确率的数据，这里用的是准确率。Val_accuracy验证准确率。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" 执行训练过程\n\n")])])]),s("p",[t._v("Model.fit(train_images训练图片，train_labels训练标签，epochs训练轮次)")]),t._v(" "),s("p",[t._v("模型训练时会显示损失和准确率指标。在训练数据集上，损失loss可能会较小，从而识别的准确率可能会达到较高的一个水平。但是在测试数据集上，损失loss可能会高于训练数据集，而准确率相较于训练数据集有所下降。")]),t._v(" "),s("p",[t._v("二者在准确率上的差值代表过拟合，过拟合是指机器学习的模型在新的、从未见过的输入上的表现不如在训练集上的表现。过拟合的模型会记住训练数据集中的噪声和细节，从而对新模型在新数据上产生负面影响。")]),t._v(" "),s("h2",{attrs:{id:"回归问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#回归问题"}},[t._v("#")]),t._v(" 回归问题")]),t._v(" "),s("p",[t._v("识别的目的是为了分类，回归问题是为了预测。通过观测自变量对因变量的影响，去预估在一个新的自变量下因变量的值。")]),t._v(" "),s("p",[t._v('Dataset_path=keras.utils.get_file("文件名","文件加载地址")\n从文件加载地址下载文件，并赋给datasets')]),t._v(" "),s("p",[t._v("pandas数据分析库，pd.read_csv( )  读取csv文件，路径可以是某个有具体内容的具体路径，也可以是某个网址。")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("\ndataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isna"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   发现数据中的缺失值并统计数量\n\ndataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    删除具有缺失值的行\n\ntrain_dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("frac"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntest_dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("p",[t._v("对训练集进行随机拆分，sample表示随机取出百分之多少")]),t._v(" "),s("p",[t._v("均方误差常用于回归问题的损失函数，而分类问题中常用交叉熵函数作为损失函数；")]),t._v(" "),s("p",[t._v("用于回归的评估指标与分类也不同，常见的回归指标是平均绝对误差（MAE）\n而分类问题常常以损失函数的大小和验证精度作为评价指标；")]),t._v(" "),s("p",[t._v("当数字输入数据特征的值存在不同范围时，每个特征应该独立缩放到相同范围；\n当训练数据不多时，可以选择隐藏层较少的小网络，避免网络结构的过拟合；\n早期停止训练是一种防止过拟合的有效技术。")]),t._v(" "),s("h2",{attrs:{id:"过拟合与欠拟合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#过拟合与欠拟合"}},[t._v("#")]),t._v(" 过拟合与欠拟合")]),t._v(" "),s("p",[t._v("在模型的训练中，模型在训练集上的损失值呈下降趋势，精度呈上升趋势。然而在验证数据集中，模型的损失值经过最初的下降后会有一定程度的上升，相应的精度也会在上升之后有一定的下降。")]),t._v(" "),s("p",[t._v("通常模型会在训练集上达到较高的准确率，这是因为在训练过程中，模型中的所有参数都在努力满足预定的标签值。当参数无比契合训练集时，此时用验证集去测试，这些参数就难以满足需要，自然准确率难以达到训练集的程度，甚至有所下降。")]),t._v(" "),s("p",[t._v("过拟合的反面是欠拟合，当在测试数据上仍有改进空间时就会发生欠拟合。出现这种情况的原因有很多，如：模型不够强大，过度正则化或者训练过少。这就是网络尚未能学习到训练数据的精髓。")]),t._v(" "),s("p",[t._v("当训练时间过长，模型开始过拟合，并从训练数据中学习到无法泛化的参数时，就会对再次识别新事物产生困难。")]),t._v(" "),s("p",[t._v("相比于泛化而言，过拟合往往是更容易达到的一个。我们想要的是一个过拟合和泛化的平衡点：既不会过拟合难以泛化，也不会泛化过大，导致准确率过低。\n防止过拟合：")]),t._v(" "),s("p",[t._v("1、使用更为完备的数据集。训练数据集要涵盖模型要处理的所有输入，其他数据可能只有在涉及到新的、值得关注的情况时才会用到。")]),t._v(" "),s("p",[t._v("2、正则化。在数据不足时，使模型更加关注最突出的那些信息。哪些信息对结果的影响更大，就更加突出它的地位。")]),t._v(" "),s("h2",{attrs:{id:"保存和恢复模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#保存和恢复模型"}},[t._v("#")]),t._v(" 保存和恢复模型")]),t._v(" "),s("p",[t._v("模型：代码+训练的权重和参数")]),t._v(" "),s("p",[t._v("pip install pyyaml h5py")]),t._v(" "),s("p",[t._v("h5py的优势：速度快、压缩效率高，总之，numpy.savez和cPickle存储work或不work的都可以试一试h5py！h5py文件是存放两类对象的容器，数据集(dataset)和组(group)，dataset类似数组类的数据集合，和numpy的数组差不多。group是像文件夹一样的容器，它好比python中的字典，有键(key)和值(value)。group中可以存放dataset或者其他的group。”键”就是组成员的名称，”值”就是组成员对象本身(组或者数据集)，下面来看下如何创建组和数据集。")]),t._v(" "),s("p",[t._v("os.path.dirname   去掉文件名返回文件的目录")]),t._v(" "),s("p",[t._v("在模型的训练过程中，常常以checkpoint文件（后缀为.ckpt）保存训练后的参数信息。而在原有基础上再次训练时，往往会用Keras中的callbacks函数去调用该文件。")]),t._v(" "),s("p",[t._v("也可以重新创建一个结构和已经训练的模型一致的未训练模型，然后使用load_weights(文件路径)  加载该文件路径中存储的参数。")]),t._v(" "),s("p",[t._v("在保存和恢复中，常常要用到call_back函数去调用已经生成的ckpt文件。\n新的模型和调用预训练过的参数的模型二者的精确度有较为明显的差别。")]),t._v(" "),s("h2",{attrs:{id:"调整超参数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#调整超参数"}},[t._v("#")]),t._v(" 调整超参数")]),t._v(" "),s("p",[t._v("Keras.tuner库   调整超参数，选择最佳的超参数")]),t._v(" "),s("p",[t._v("超参数：是控制训练过程和ML模型拓扑的变量。这些变量在训练过程中保持不变，并会直接影响ML程序的性能。")]),t._v(" "),s("p",[t._v("模型拓扑：在原有的基础上进行模型的重新绘制，产生非常高效的模型。")]),t._v(" "),s("p",[t._v("模型超参数：影响模型的选择，例如隐藏层的数量和宽度")]),t._v(" "),s("p",[t._v("算法超参数：影响学习算法的速度和质量，例如随机梯度下降的学习率以及K近邻（knn）分类器的近邻数")])])}),[],!1,null,null,null);a.default=e.exports}}]);
<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>TensorFlow笔记（1） | 周清冽</title>
    <meta name="generator" content="VuePress 1.7.1">
    <link rel="icon" href="false">
    <script>
          var _hmt = _hmt || [];
          (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?b0aae218897fa9d8a9f76e9a77e0b3c6";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
          })();
        </script>
    <meta name="description" content="记录我的生活">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.46b311ed.css" as="style"><link rel="preload" href="/assets/js/app.c50e37c9.js" as="script"><link rel="preload" href="/assets/js/5.3a253b5d.js" as="script"><link rel="preload" href="/assets/js/1.cc71daf5.js" as="script"><link rel="preload" href="/assets/js/28.09a12566.js" as="script"><link rel="prefetch" href="/assets/js/10.fa7958e2.js"><link rel="prefetch" href="/assets/js/11.db34a267.js"><link rel="prefetch" href="/assets/js/12.47e95deb.js"><link rel="prefetch" href="/assets/js/13.149411d2.js"><link rel="prefetch" href="/assets/js/14.c2d5aa0c.js"><link rel="prefetch" href="/assets/js/15.0dfeb754.js"><link rel="prefetch" href="/assets/js/16.1d85cf19.js"><link rel="prefetch" href="/assets/js/17.939ba57f.js"><link rel="prefetch" href="/assets/js/18.4de2d514.js"><link rel="prefetch" href="/assets/js/19.fb88e8a2.js"><link rel="prefetch" href="/assets/js/20.e03fdd3a.js"><link rel="prefetch" href="/assets/js/21.1146c9a1.js"><link rel="prefetch" href="/assets/js/22.e59be7c2.js"><link rel="prefetch" href="/assets/js/23.cc236a82.js"><link rel="prefetch" href="/assets/js/24.31f55451.js"><link rel="prefetch" href="/assets/js/25.5a02ab8e.js"><link rel="prefetch" href="/assets/js/26.9f4e234b.js"><link rel="prefetch" href="/assets/js/27.ff0c425b.js"><link rel="prefetch" href="/assets/js/29.c64fdafd.js"><link rel="prefetch" href="/assets/js/3.0692ab67.js"><link rel="prefetch" href="/assets/js/30.5b7dd487.js"><link rel="prefetch" href="/assets/js/31.acdbc643.js"><link rel="prefetch" href="/assets/js/32.84e04aee.js"><link rel="prefetch" href="/assets/js/33.2761c02c.js"><link rel="prefetch" href="/assets/js/34.e33ad4e3.js"><link rel="prefetch" href="/assets/js/35.dfc93c4a.js"><link rel="prefetch" href="/assets/js/36.5139b2a4.js"><link rel="prefetch" href="/assets/js/37.87b21aad.js"><link rel="prefetch" href="/assets/js/38.cbe48101.js"><link rel="prefetch" href="/assets/js/39.43445161.js"><link rel="prefetch" href="/assets/js/4.dbb40325.js"><link rel="prefetch" href="/assets/js/40.981db936.js"><link rel="prefetch" href="/assets/js/6.97497809.js"><link rel="prefetch" href="/assets/js/7.12ba85fa.js"><link rel="prefetch" href="/assets/js/8.e959cd54.js"><link rel="prefetch" href="/assets/js/9.48191f15.js">
    <link rel="stylesheet" href="/assets/css/0.styles.46b311ed.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-106e3130><div data-v-106e3130><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-106e3130 data-v-106e3130><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4d3be7b7 data-v-106e3130 data-v-106e3130><h3 class="title" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7>周清冽</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7><input type="password" value="" data-v-4d3be7b7> <span data-v-4d3be7b7>Konck! Knock!</span> <button data-v-4d3be7b7>OK</button></label> <div class="footer" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7><span data-v-4d3be7b7><i class="iconfont reco-theme" data-v-4d3be7b7></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4d3be7b7>vuePress-theme-reco</a></span> <span data-v-4d3be7b7><i class="iconfont reco-copyright" data-v-4d3be7b7></i> <a data-v-4d3be7b7><span data-v-4d3be7b7>周清冽</span>
            
          <!---->
          2023
        </a></span></div></div> <div class="hide" data-v-106e3130><div data-v-106e3130><div id="smart" class="wrapper-page" style="background-image:url(https://img1.imgtp.com/2023/05/26/NoMFtgx7.jpg);background-position-x:center;background-position-y:center;background-size:cover;background-repeat-x:no-repeat;background-repeat-y:no-repeat;" data-v-106e3130><header class="navbar" data-v-106e3130><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/avatar.png" alt="周清冽" class="logo"> <span class="site-name">周清冽</span></a> <div class="links"><div id="dayNightSwitch" class="generalWrapper" data-v-68728e36><a class="click" data-v-68728e36><div class="onOff daySwitch" data-v-68728e36><div class="star star1" data-v-68728e36></div> <div class="star star2" data-v-68728e36></div> <div class="star star3" data-v-68728e36></div> <div class="star star4" data-v-68728e36></div> <div class="star star5" data-v-68728e36></div> <div class="star sky" data-v-68728e36></div> <div class="sunMoon" data-v-68728e36><div class="crater crater1" data-v-68728e36></div> <div class="crater crater2" data-v-68728e36></div> <div class="crater crater3" data-v-68728e36></div> <div class="cloud part1" data-v-68728e36></div> <div class="cloud part2" data-v-68728e36></div></div></div></a></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/技术笔记/" class="nav-link"><i class="iconfont undefined"></i>
  技术笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/树洞/" class="nav-link"><i class="iconfont undefined"></i>
  树洞
</a></li><li class="dropdown-item"><!----> <a href="/categories/神经网络/" class="nav-link"><i class="iconfont undefined"></i>
  神经网络
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><a href="/about/" class="nav-link"><i class="iconfont reco-account"></i>
  关于
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-106e3130></div> <aside class="sidebar" data-v-106e3130><div class="personal-info-wrapper" data-v-d528efe2 data-v-106e3130><img src="/avatar.png" alt="author-avatar" class="personal-img" data-v-d528efe2> <h3 class="name" data-v-d528efe2>
    周清冽
  </h3> <div class="num" data-v-d528efe2><div data-v-d528efe2><h3 data-v-d528efe2>27</h3> <h6 data-v-d528efe2>文章</h6></div> <div data-v-d528efe2><h3 data-v-d528efe2>6</h3> <h6 data-v-d528efe2>标签</h6></div></div> <hr data-v-d528efe2></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/技术笔记/" class="nav-link"><i class="iconfont undefined"></i>
  技术笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/树洞/" class="nav-link"><i class="iconfont undefined"></i>
  树洞
</a></li><li class="dropdown-item"><!----> <a href="/categories/神经网络/" class="nav-link"><i class="iconfont undefined"></i>
  神经网络
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><a href="/about/" class="nav-link"><i class="iconfont reco-account"></i>
  关于
</a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4d3be7b7 data-v-106e3130><h3 class="title" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7>TensorFlow笔记（1）</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7><input type="password" value="" data-v-4d3be7b7> <span data-v-4d3be7b7>Konck! Knock!</span> <button data-v-4d3be7b7>OK</button></label> <div class="footer" style="display:none;" data-v-4d3be7b7 data-v-4d3be7b7><span data-v-4d3be7b7><i class="iconfont reco-theme" data-v-4d3be7b7></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4d3be7b7>vuePress-theme-reco</a></span> <span data-v-4d3be7b7><i class="iconfont reco-copyright" data-v-4d3be7b7></i> <a data-v-4d3be7b7><span data-v-4d3be7b7>周清冽</span>
            
          <!---->
          2023
        </a></span></div></div></div> <div data-v-106e3130><main class="page" style="padding-right:0;"><div class="page-title" style="display:none;"><h1 class="title">TensorFlow笔记（1）</h1> <div class="page-info" data-v-04a855f8><i class="iconfont reco-account" data-v-04a855f8><span data-v-04a855f8>周清冽</span></i> <i class="iconfont reco-date" data-v-04a855f8><span data-v-04a855f8>2022-11-12</span></i> <i class="iconfont reco-eye" data-v-04a855f8><span id="/blogs/tensor/ten01.html" data-flag-title="Your Article Title" class="leancloud-visitors" data-v-04a855f8><a class="leancloud-visitors-count" style="font-size:.9rem;font-weight:normal;color:#999;"></a></span></i> <i class="iconfont reco-tag tags" data-v-04a855f8><span class="tag-item" data-v-04a855f8>tensorflow</span></i></div></div> <div class="theme-reco-content content__default" style="display:none;"><div class="custom-block tip"><p>基础知识及鸢尾花识别实例解析<br></p></div> <p>人工智能的主流：连接主义。</p> <h3 id="人工智能的三个学派"><a href="#人工智能的三个学派" class="header-anchor">#</a> 人工智能的三个学派：</h3> <p>1、行为主义：基于控制论，由感知到控制。</p> <p>2、符号主义：基于表达式，先描述表达式，再求解表达式，是一种用公式描述的人工智能。</p> <p>3、连接主义：仿生学，神经网络的感性控制。</p> <h3 id="搭建一个完整的神经网络-往往需要以下几个步骤"><a href="#搭建一个完整的神经网络-往往需要以下几个步骤" class="header-anchor">#</a> 搭建一个完整的神经网络，往往需要以下几个步骤：</h3> <p>1、准备数据：特征和标签对（数据集）</p> <p>2、搭建网络：确定神经网络的结构</p> <p>3、优化参数：（利用反向传播）获取最佳参数</p> <p>4、应用网络：保存训练模型，应用（前向传播）</p> <p>神经网络的表达式：y=w*x+b     y表示期望，w表示权重，b表示偏置，在最初的设计中，w和b都是随机设置的。</p> <p>损失函数：预测期望值与实际值的差距，根据损失函数去判断参数w、b优化的好坏，是否还需要继续优化。常见的是均方误差（MSE），目的就是找到使损失函数最小的w和b。</p> <p>梯度：损失函数对各参数求偏导后的向量，梯度下降的方向即损失函数变小的方向，沿着梯度的下降方向寻找损失函数的最小值。</p> <p>迭代函数：wt=wt-lr*（loss对w的偏导）    wt表示参数，lr表示迭代速率</p> <h3 id="tensor-张量-多维数组"><a href="#tensor-张量-多维数组" class="header-anchor">#</a> Tensor：张量，多维数组</h3> <p>拥有的数据类型：int、float（32,64）、bool、string</p> <p>创建张量tensor：tf.constant(张量内容，形状，dtype=数据类型)</p> <p>张量内容如果是一个数值，那么在张量内部都会填充为该数值。</p> <p>tf.constant([1 5], shape=(2，)， dtype=int64)    表示是一个两行，第一行为1第二行为5的整型张量。</p> <p>对于numpy格式的数据，要用tf.convert_to_tensor(a,dtype=)转变为tensor。</p> <p>创建全为0的张量：tf.zeros(维度)</p> <p>创建全为1的张量：tf.ones（维度）</p> <p>创建全为指定值的张量：tf.fill（维度，指定值）</p> <p>生成正态分布的随机数，默认均值为0，标准差为1   tf.random.normal(维度，mean=均值，stddev=标准差)</p> <p>生成截断式正态分布的随机数   tf.random.truncated_normal(维度，mean=均值，stddev=标准差)</p> <p>生成均匀分布随机数   tf.random.uniform(维度，minval=最小值，maxval=最大值) 最小最大为前闭后开区间</p> <h3 id="常见函数"><a href="#常见函数" class="header-anchor">#</a> 常见函数：</h3> <p>强制转换类型函数：tf.cast（A张量名，dtype=数据类型）  表明要将张量A转变为dtype后的数据类型</p> <p>计算张量维度元素上的最小值：tf.reduce_min（张量A）</p> <p>计算张量维度元素上的最大值：tf.reduce_max（张量A）</p> <p>axis：指定axis等于0或1，来控制被执行的行与列。</p> <p>axis=0，表示沿着行垂直往下（列）；axis=1，表示沿着列水平向右（行），如果不指定axis，则所有元素都参与计算。</p> <p>tf.varuable(初始值)：</p> <p>将变量标记为“可训练”，被标记的变量会在反向传播中记录梯度信息。神经网络训练汇总，常用该函数标记带训练参数。</p> <h3 id="四则运算"><a href="#四则运算" class="header-anchor">#</a> 四则运算：</h3> <p>tf.add/subtract/multiply/divide（张量1，张量2），分别表示+-*/，只有相同维度的张量才可以进行四则运算。</p> <p>平方：tf.square(张量)</p> <p>次方：tf.pow(张量)</p> <p>开方：tf.sqrt(张量）</p> <p>矩阵乘：tf.matmul（a，b）   a，b必须符合矩阵的运算要求</p> <h3 id="鸢尾花实例及解析"><a href="#鸢尾花实例及解析" class="header-anchor">#</a> 鸢尾花实例及解析：</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># -*- coding: UTF-8 -*-</span>
<span class="token comment"># UTF-8编码解码器，使计算机能正确识别中文</span>
<span class="token comment"># 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线</span>

<span class="token comment"># 导入所需模块</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf  <span class="token comment">#引入tensorflow包，并重命名为tf，后续的tf即表示tensorflow（用于神经网络搭建）</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets   <span class="token comment">#从sklearn包下载datasets数据集</span>
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt   <span class="token comment">#从matplotlib包引入pyplot函数，并重命名为plt（用于记录数据绘图输出图形）</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np   <span class="token comment">#引入numpy包重命名为np（用于数值计算和数据扩展）</span>
<span class="token comment">#一、准备数据</span>
<span class="token comment"># ①数据集读入</span>
<span class="token comment"># 导入数据，分别为输入特征和标签</span>
x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data  <span class="token comment">#表示从datasets加载iris的特征数据</span>
y_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target  <span class="token comment">#表示从datasets加载iris的标签</span>
<span class="token comment">#②数据集乱序</span>
<span class="token comment"># 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）</span>
<span class="token comment"># seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样</span>
<span class="token comment"># shuffle用来吧一个列表中的元素顺序随机打乱</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>  <span class="token comment"># 使用相同的seed，保证输入特征和标签一一对应，先设置随机数，再执行乱序的shuffle操作</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>   <span class="token comment">#设置操作级别的种子数</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>
<span class="token comment"># 此时x与y被打乱，但二者的特征和标签仍旧一一对应</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>    <span class="token comment">#设置全局种子数</span>
<span class="token comment">#③生成训练集及测试集</span>
<span class="token comment"># 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行</span>
x_train <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
y_train <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
x_test <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y_test <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment"># 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错</span>
<span class="token comment"># 矩阵相乘时要求数据类型是一致的</span>
x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment">#转换类型</span>
x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment">#同上</span>
<span class="token comment">#④配成（输入特征与标签对），每次读入一小撮</span>
<span class="token comment"># from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）</span>
train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
<span class="token comment"># 将训练组的x与y对应起来，后边加.batch表示将该数据组按照每32个一组组成一个batch</span>
test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
<span class="token comment"># 将测试组的x与y对应起来</span>

<span class="token comment"># 二搭建神经网络</span>
<span class="token comment"># 生成神经网络的参数，4个输入特征（鸢尾花有四个特征测量数据），输入层为4个输入节点；因为3分类，故输出层为3个神经元</span>
<span class="token comment"># 用tf.Variable()标记参数可训练</span>
<span class="token comment"># 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）</span>
w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#标记w1是可训练参数，然后随机生成一个截取正态范围内的一部分作为随机数生成的区间（表示生成了一个四行三列，标准差为0.1，随机种子为1的矩阵）</span>
b1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># b1作为偏置项，衡量的是一个神经元激活的难易程度，越大越难以被激活，通过对b的优化，使各个神经元达到最合适的激活状态</span>
lr <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># 学习率为0.1，即沿着梯度下降方向的步长</span>
train_loss_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 定义了一个列表（()为元组不可变，[]为列表可变，{}为字典），将每轮的loss记录在此列表中，为后续画loss曲线提供数据</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 定义了一个列表，将每轮的acc记录在此列表中，为后续画acc曲线提供数据</span>
epoch <span class="token operator">=</span> <span class="token number">500</span>  <span class="token comment"># 循环500轮</span>
loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 每轮分4个step，loss_all记录四个step生成的4个loss的和</span>

<span class="token comment"># 训练部分</span>
<span class="token comment"># 120个数据分为每32个数据一组，进行训练。训练500epoch（轮）</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#for循环进行迭代训练（for往往针对的是次数已知的循环，while针对的是次数未知的），数据集级别的循环，每个epoch循环一次数据集</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#batch级别的循环 ，每个step循环一个batch</span>
        <span class="token comment"># enumerate函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>  <span class="token comment"># with，上下文管理器，该结构记录梯度信息</span>
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1  <span class="token comment"># 神经网络矩阵乘法与加法运算，完成y=w*x+b的运算</span>
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 使输出y（预测值）符合概率分布（此操作后与独热码同量级，可相减求loss）</span>
            <span class="token comment"># softmax层的输入是全连接，输出是0-1之间的一个概率值，取最大的为输出结果</span>
            y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 将标签值（实际值）转换为独热码格式，方便计算loss和accuracy</span>
            loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_ <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 损失函数采用均方误差mse = mean(sum(y-out)^2)，可以消除正负值带来的影响</span>
            loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确</span>
        <span class="token comment"># 计算loss对各个参数的梯度</span>
        grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> <span class="token punctuation">[</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># gradient函数，求梯度</span>
        <span class="token comment"># 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad</span>
        w1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数w1自更新，assign_sub 自减</span>
        b1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 参数b自更新</span>

    <span class="token comment"># 对每个epoch，打印loss信息</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Epoch {}, loss: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> loss_all<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_loss_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_all <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># 给train_loss_results追加内容，将4个step的loss求平均记录在此变量中</span>
    loss_all <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># loss_all归零，为记录下一个epoch的loss做准备</span>

    <span class="token comment"># 测试部分</span>
    <span class="token comment"># total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0</span>
    total_correct<span class="token punctuation">,</span> total_number <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>
    <span class="token keyword">for</span> x_test<span class="token punctuation">,</span> y_test <span class="token keyword">in</span> test_db<span class="token punctuation">:</span>
        <span class="token comment"># 使用更新后的参数进行预测</span>
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># argmax 返回y中最大值的索引，即预测的分类</span>
        <span class="token comment"># 将pred转换为y_test的数据类型</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dtype<span class="token operator">=</span>y_test<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>  <span class="token comment">#cast 强制转换数据类型，后边跟某个变量，指的是转变成该变量的格式</span>
        <span class="token comment"># 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>   <span class="token comment">#比较pred和y_test的数据类型，二者的形式要一致，否则不能进行比较</span>
        <span class="token comment"># 相同输出true，不同输出false</span>
        <span class="token comment"># 将每个batch的correct数加起来</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
        <span class="token comment"># 将所有batch中的correct数加起来</span>
        total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
        <span class="token comment"># total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数，0表示返回一个数</span>
        total_number <span class="token operator">+=</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># 总的准确率等于total_correct/total_number</span>
    acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_number
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Test_acc:&quot;</span><span class="token punctuation">,</span> acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;--------------------------&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制 loss 曲线，plt绘图函数</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Loss Function Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss_results<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&quot;$Loss$&quot;</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出trian_loss_results值并连线，连线图标是Loss</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出曲线图标</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 画出图像</span>

<span class="token comment"># 绘制 Accuracy 曲线</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Acc Curve'</span><span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>  <span class="token comment"># x轴变量名称</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Acc'</span><span class="token punctuation">)</span>  <span class="token comment"># y轴变量名称</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&quot;$Accuracy$&quot;</span><span class="token punctuation">)</span>  <span class="token comment"># 逐点画出test_acc值并连线，连线图标是Accuracy</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit" style="display:none;"><!----> <!----></footer> <!----> <!----> <!----></main> <!----></div></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><canvas id="vuepress-canvas-cursor"></canvas><div></div><div class="reco-bgm-panel" data-v-b1d3339e><audio id="bgm" src="/bgm/dbmy.mp3" data-v-b1d3339e></audio> <div class="reco-float-box" style="bottom:80px;z-index:999999;display:none;" data-v-b1d3339e data-v-41bcba48 data-v-b1d3339e><img src="/bgm/dbmy.png" data-v-b1d3339e></div> <div class="reco-bgm-box" style="left:10px;bottom:10px;z-index:999999;" data-v-b1d3339e data-v-41bcba48 data-v-b1d3339e><div class="reco-bgm-cover" style="background-image:url(/bgm/dbmy.png);" data-v-b1d3339e><div class="mini-operation" style="display:none;" data-v-b1d3339e><i class="reco-bgm reco-bgm-pause" style="display:none;" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-play" style="display:none;" data-v-b1d3339e></i></div> <div class="falut-message" style="display:none;" data-v-b1d3339e>
          播放失败
        </div></div> <div class="reco-bgm-info" data-v-b1d3339e data-v-41bcba48 data-v-b1d3339e><div class="info-box" data-v-b1d3339e><i class="reco-bgm reco-bgm-music music" data-v-b1d3339e></i>东北民谣</div> <div class="info-box" data-v-b1d3339e><i class="reco-bgm reco-bgm-artist" data-v-b1d3339e></i>毛不易</div> <div class="reco-bgm-progress" data-v-b1d3339e><div class="progress-bar" data-v-b1d3339e><div class="bar" data-v-b1d3339e></div></div></div> <div class="reco-bgm-operation" data-v-b1d3339e><i class="reco-bgm reco-bgm-last last" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-pause pause" style="display:none;" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-play play" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-next next" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-volume1 volume" data-v-b1d3339e></i> <i class="reco-bgm reco-bgm-mute mute" style="display:none;" data-v-b1d3339e></i> <div class="volume-bar" data-v-b1d3339e><div class="bar" data-v-b1d3339e></div></div></div></div> <div class="reco-bgm-left-box" data-v-b1d3339e data-v-41bcba48 data-v-b1d3339e><i class="reco-bgm reco-bgm-left" data-v-b1d3339e></i></div></div></div></div></div>
    <script src="/assets/js/app.c50e37c9.js" defer></script><script src="/assets/js/5.3a253b5d.js" defer></script><script src="/assets/js/1.cc71daf5.js" defer></script><script src="/assets/js/28.09a12566.js" defer></script>
  </body>
</html>
